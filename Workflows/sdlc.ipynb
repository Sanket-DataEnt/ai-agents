{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 30, 'total_tokens': 40, 'completion_time': 0.05, 'prompt_time': 0.003685376, 'queue_time': 0.053871884, 'total_time': 0.053685376}, 'model_name': 'qwen-2.5-32b', 'system_fingerprint': 'fp_c527211fd1', 'finish_reason': 'stop', 'logprobs': None}, id='run-b8f2fcdb-b5b7-44f9-bd7d-85b16ffe8ee9-0', usage_metadata={'input_tokens': 30, 'output_tokens': 10, 'total_tokens': 40})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "llm=ChatGroq(model=\"qwen-2.5-32b\")\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result=llm.invoke(\"Hello\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### State\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_input: str\n",
    "    user_input_requirements: str\n",
    "    user_stories: str\n",
    "    po_review: str\n",
    "    design_documents: str\n",
    "    revised_user_stories: str\n",
    "    code: str\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes Definition\n",
    "\n",
    "def UserInputRequirements(state: State):\n",
    "    \"\"\"LLM Call to get the requirements for the user input\"\"\"\n",
    "        # Use the LLM to generate requirements based on the user input\n",
    "    prompt = f\"Write a clear and concise description of the requirements for the following user input: {state['user_input']}\"\n",
    "    response = llm.invoke(prompt)\n",
    "     # Extract the generated requirements from the LLM response\n",
    "    requirements = response.content\n",
    "    return {\"user_input_requirements\": requirements}\n",
    "\n",
    "def AutoGenerateUserStories(state: State):\n",
    "    \"\"\"LLM Call to auto-generate user stories\"\"\"\n",
    "    # Use the LLM to generate user stories based on the user input and requirements\n",
    "    prompt = f\"Write user stories in the format 'As a [user], I want to [perform some task] so that [achieve some goal]' for the following user input and requirements: {state['user_input']}. Requirements: {state['user_input_requirements']}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    # Extract the generated user stories from the LLM response\n",
    "    user_stories = response.content\n",
    "    return {\"user_stories\": user_stories}\n",
    "\n",
    "def ProdutOwnerReview(state: State):\n",
    "    \"\"\"Product Owner reviews the user stories\"\"\"\n",
    "    # Product Owner reviews the user stories and provides feedback\n",
    "    # user_stories = state[\"user_stories\"]\n",
    "    prompt = f\"Provide suggestions to improve the clarity and conciseness of the following user stories: {state['user_stories']} accordingly it will be Approved or it needs some changes i.e Feedback\"\n",
    "    response = llm.invoke(prompt)\n",
    "    feedback = response.content\n",
    "    # feedback = \"The user stories are clear and concise. I approve them.\"\n",
    "    return {\"po_review\": feedback}\n",
    "\n",
    "def Check_ProdutOwnerReview(state: State):\n",
    "    \"\"\"Check if the Product Owner has approved the user stories\"\"\"\n",
    "    po_review = state[\"po_review\"]\n",
    "    # Check if the Product Owner has approved the user stories\n",
    "    # Use a case-insensitive check for keywords indicating approval\n",
    "    approval_keywords = [\"approve\", \"approved\", \"accept\", \"accepted\"]\n",
    "    if any(keyword in po_review.lower() for keyword in approval_keywords):\n",
    "        return \"Approved\"\n",
    "    else:\n",
    "        return \"Feedback\"\n",
    "\n",
    "def DesignDocuments(state: State):\n",
    "    \"\"\"Create Design Docuemnents - Functional and technical\"\"\"\n",
    "    # Create design documents based on the user stories\n",
    "    # user_stories = state[\"user_stories\"]\n",
    "    prompt = f\"Create detailed functional and technical design documents for the following approved user stories: {state['user_stories']}. Ensure the documents include system architecture, data flow, and key technical specifications. Make sure that user stories to consider here should be approved by the Product Owner.\"\n",
    "    response = llm.invoke(prompt)\n",
    "    design_documents = response.content\n",
    "    return {\"design_documents\": design_documents}\n",
    "\n",
    "def ReviseUserStories(state: State):\n",
    "    \"\"\"Revise user stories based on the Feedback from the Product Owner Review\"\"\"\n",
    "    feedback = state[\"po_review\"]\n",
    "    # user_stories = state[\"user_stories\"]\n",
    "    prompt = f\"Revise the following user stories based on the feedback provided by the Product Owner: {state['user_stories']}. Feedback: {feedback}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    revised_user_stories = response.content\n",
    "    return {\"revised_user_stories\": revised_user_stories}\n",
    "\n",
    "def DesignReview(state: State):\n",
    "    \"\"\"Review of the Design Documents by the Product Owner\"\"\"\n",
    "    design_documents = state[\"design_documents\"]\n",
    "    prompt = f\"Review the following design documents : {design_documents} and provide feedback whether it meets the requirements accordingly it will be Approved or it needs some changes i.e Feedback\"\n",
    "    response = llm.invoke(prompt)\n",
    "    feedback = response.content\n",
    "    return {\"design_review\": feedback}\n",
    "\n",
    "\n",
    "def Check_DesignReview(state: State):\n",
    "    \"\"\"Do the check of the Design Review\"\"\"\n",
    "    design_review = state[\"design_review\"]\n",
    "    # Check if the Product Owner has approved the design documents\n",
    "    # Use a case-insensitive check for keywords indicating approval\n",
    "    approval_keywords = [\"approve\", \"approved\", \"accept\", \"accepted\"]\n",
    "    if any(keyword in design_review.lower() for keyword in approval_keywords):\n",
    "        return \"Approved\"\n",
    "    else:\n",
    "        return \"Feedback\"\n",
    "    \n",
    "def GenerateCode(state: State):\n",
    "    \"\"\"Generate Code based on the Design Documents\"\"\"\n",
    "    # Generate code based on the design documents\n",
    "    # design_documents = state[\"design_review\"]\n",
    "    prompt = f\"Generate code based on the following approved design documents: {state['design_documents']} and {state['design_review']}. Ensure the code is clean, well-documented, and follows best practices.\"\n",
    "    response = llm.invoke(prompt)\n",
    "    code = response.content\n",
    "    return {\"code\": code}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Worklow\n",
    "\n",
    "workflow = StateGraph()\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"UserInputRequirements\", UserInputRequirements)\n",
    "workflow.add_node(\"AutoGenerateUserStories\", AutoGenerateUserStories)\n",
    "# workflow.add_node(\"ProdonutOwnerReview\", Check_ProdutOwnerReview, {\"Approved\":\"DesignDocuments\", \"Feedback\":\"ReviseUserStories\"})\n",
    "workflow.add_node(\"ProdutOwnerReview\", ProdutOwnerReview)\n",
    "workflow.add_node(\"DesignDocuments\", DesignDocuments)\n",
    "workflow.add_node(\"ReviseUserStories\", ReviseUserStories)\n",
    "workflow.add_node(\"DesignReview\", DesignReview)\n",
    "workflow.add_node(\"GenerateCode\", GenerateCode)\n",
    "workflow.add_node(\"CodeReview\", CodeReview)\n",
    "workflow.add_node(\"SecurityReview\", SecurityReview)\n",
    "workflow.add_node(\"FixCode\", FixCode)\n",
    "workflow.add_node(\"WriteTestCases\", WriteTestCases)\n",
    "workflow.add_node(\"FixCodeSecurity\", FixCodeSecurity)\n",
    "workflow.add_node(\"TestCasesReview\", TestCasesReview)\n",
    "workflow.add_node(\"QATesting\", QATesting)\n",
    "workflow.add_node(\"FixTestCases\", FixTestCases)\n",
    "workflow.add_node(\"FixCode\", FixCode)\n",
    "workflow.add_node(\"Deploy\", Deploy)\n",
    "workflow.add_node(\"MonitorFeedback\", MonitorFeedback)\n",
    "workflow.add_node(\"MaintenanceUpdate\", MaintenanceUpdate)\n",
    "\n",
    "\n",
    "# Add Edges\n",
    "workflow.add_edge(START, \"UserInputRequirements\")\n",
    "workflow.add_edge(\"UserInputRequirements\", \"AutoGenerateUserStories\")\n",
    "workflow.add_edge(\"AutoGenerateUserStories\", \"ProdutOwnerReview\")\n",
    "workflow.add_conditional_edges(\"ProdutOwnerReview\", Check_ProdutOwnerReview, {\"Approved\":\"DesignDocuments\", \"Feedback\":\"ReviseUserStories\"})\n",
    "workflow.add_edge(\"ReviseUserStories\", \"AutoGenerateUserStories\")\n",
    "workflow.add_edge(\"DesignDocuments\", \"DesignReview\")\n",
    "workflow.add_conditional_edges(\"DesignReview\", Check_DesignReview, {\"Approved\":\"GenerateCode\", \"Feedback\":\"DesignDocuments\"})\n",
    "workflow.add_edge(\"GenerateCode\", \"CodeReview\")\n",
    "workflow.add_conditional_edges(\"CodeReview\", Check_CodeReview, {\"Approved\":\"SecurityReview\", \"Feedback\":\"FixCode\"})\n",
    "workflow.add_edge(\"FixCode\", \"GenerateCode\")\n",
    "workflow.add_conditional_edges(\"SecurityReview\", Check_SecurityReview, {\"Approved\":\"WriteTestCases\", \"Feedback\":\"FixCodeSecurity\"})\n",
    "workflow.add_edge(\"FixCodeSecurity\", \"GenerateCode\")\n",
    "workflow.add_edge(\"WriteTestCases\", \"TestCasesReview\")\n",
    "workflow.add_conditional_edges(\"TestCasesReview\", Check_TestCasesReview, {\"Approved\":\"QATesting\", \"Feedback\":\"FixTestCases\"})\n",
    "workflow.add_edge(\"FixTestCases\", \"WriteTestCases\")\n",
    "workflow.add_conditional_edges(\"QATesting\", Check_QATesting, {\"Passed\":\"Deploy\", \"Failed\":\"FixCode\"})\n",
    "workflow.add_edge(\"FixCode\", \"GenerateCode\")\n",
    "workflow.add_edge(\"Deploy\", \"MonitorFeedback\")\n",
    "workflow.add_edge(\"MonitorFeedback\", \"MaintenanceUpdate\")\n",
    "workflow.add_edge(\"MaintenanceUpdate\", END)\n",
    "\n",
    "# Compile Workflow\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Show workflow\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
